{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Satcen Finetuning\n",
    "\n",
    "Fine tune the Unet model trained on the Airbus dataset using the Satcen dataset.\n",
    "\n",
    "## Construct the Training Dataset\n",
    "\n",
    "Load and split the Satcen dataset into train and test sets.\n",
    "\n",
    "- train: 50% \n",
    "- validation: 25%\n",
    "- test: 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from PIL import Image, ImageDraw as Drawer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ijson\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# path to satcen dataset\n",
    "satcen_path = pathlib.Path('../satcen_dataset/').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Satcen images: 2170\n"
     ]
    }
   ],
   "source": [
    "# load the Satcen image filenames\n",
    "satcen = [f for f in os.listdir(satcen_path/'pictures')]\n",
    "print('Total number of Satcen images:', len(satcen))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Ground Truth Labels\n",
    "\n",
    "Compute ground truth for images in the Satcen dataset based on the given bounding boxes.\n",
    "Ground truth labels should be saved as *.png* files in the *satcen_dataset/labeled_images_binary* folder. Files should have _L at the end of the filename.\n",
    "\n",
    "In each ground truth image:\n",
    "- 0 pixel value represents background pixel\n",
    "- 1 pixel value represents ship pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute segmentation mask of a Satcen image based on its bounding box\n",
    "# @param img_name - filename of the image for which to compute ground truth\n",
    "# @param bounding_boxes - list of bounding boxes for that image\n",
    "# @param save - whether or not to save the mask\n",
    "# @param path - where to save the mask\n",
    "# @return mask - PIL image representing the mask of the given image\n",
    "def get_image_mask_satcen(img_name, bounding_boxes, path, save = False):\n",
    "    \n",
    "    # create the skeleton of the segmentation mask\n",
    "    # size is constant for satcen dataset, 256 x 256\n",
    "    mask = Image.fromarray(np.zeros((256, 256)))\n",
    "\n",
    "    # get a drawer object\n",
    "    draw = Drawer.Draw(mask)\n",
    "\n",
    "    # loop through the bounding boxes\n",
    "    for bb in bounding_boxes:\n",
    "\n",
    "        # convert coordinates to required format\n",
    "        coords = [(c['x'], c['y']) for c in bb]\n",
    "\n",
    "        # draw the bounding box on the image\n",
    "        draw.polygon(coords, fill=1)\n",
    "\n",
    "    if save:\n",
    "        mask.convert('RGB').save(path/f'{img_name[:-4]}_L.png')\n",
    "\n",
    "    return mask\n",
    "\n",
    "# load the json file containing bounding boxes\n",
    "satcen_json = [entry for entry in ijson.items(open(satcen_path/'SatCen_skiffs256.json'), 'batch.annotations.item')]\n",
    "\n",
    "# pre-process the json\n",
    "# resulting format should be\n",
    "# {name: ..., boundind_boxes: [[{'x': ..., 'y': ...}, ...], ...]}\n",
    "satcen_json = list(map(lambda x: {'name': x['name'], 'bounding_boxes': [e['data'] for e in x['objects']]}, satcen_json))\n",
    "\n",
    "# function that generates and saves masks for Satcen images\n",
    "# @param path - where to save the masks\n",
    "def save_all_satcen_masks(path):\n",
    "\n",
    "    # delete all the files in the target directory\n",
    "    for f in os.listdir(path):\n",
    "        os.remove(path/f)\n",
    "\n",
    "    # loop through all satcen images\n",
    "    for img in satcen:\n",
    "\n",
    "        # get the corresponding list of bounding boxes\n",
    "        json_entry = [e for e in satcen_json if e['name'] == img]\n",
    "        bounding_boxes = json_entry[0]['bounding_boxes'] if len(json_entry) > 0 else []\n",
    "\n",
    "        # generate and save mask\n",
    "        get_image_mask_satcen(img, bounding_boxes, path, save=True)\n",
    "\n",
    "save_all_satcen_masks(satcen_path/'labeled_images_binary')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "\n",
    "Split the entire Satcen dataset into training (50%), validation (25%) and testing (25%) datasets. Save the training and validation data in the *satcen_dataset/train_valid* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive observations: 1525 (70.27649769585254%)\n",
      "Number of negative observations: 645 (29.723502304147466%)\n"
     ]
    }
   ],
   "source": [
    "# construct the ground truth labels array\n",
    "y = []\n",
    "positives = 0\n",
    "negatives = 0\n",
    "\n",
    "# loop through all Satcen images\n",
    "for filename in satcen:\n",
    "    mask_arr = np.array(Image.open(satcen_path/'labeled_images_binary'/f'{filename[:-4]}_L.png'))\n",
    "\n",
    "    if np.any(mask_arr == 1): # positive observation\n",
    "        y.append(1) \n",
    "        positives += 1\n",
    "    else: # negative observation\n",
    "        y.append(0)\n",
    "        negatives += 1\n",
    "\n",
    "print(f'Number of positive observations: {positives} ({positives / len(satcen) * 100}%)')\n",
    "print(f'Number of negative observations: {negatives} ({negatives / len(satcen) * 100}%)')\n",
    "\n",
    "# sanity check that image filenames and corresponding ground truth label \n",
    "# are in the correct order in the array\n",
    "for i in range(len(satcen)):\n",
    "\n",
    "    img = satcen[i]\n",
    "    mask = np.array(Image.open(satcen_path/'labeled_images_binary'/f'{img[:-4]}_L.png'))\n",
    "\n",
    "    if (np.any(mask == 1) and y[i] == 0) or (not np.any(mask == 1) and y[i] == 1):\n",
    "        raise Exception('Labels do not correspond for ' + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Train Data ###\n",
      "Size: 1627\n",
      "Positive observations: 1143 (70.2519975414874%)\n",
      "Negative observations: 484 (29.7480024585126%) \n",
      "\n",
      "### Validation Data ###\n",
      "Size: 271\n",
      "Positive observations: 191 (70.47970479704797%)\n",
      "Negative observations: 80 (29.520295202952028%) \n",
      "\n",
      "### Test Data ###\n",
      "Size: 272\n",
      "Positive observations: 191 (70.22058823529412%)\n",
      "Negative observations: 81 (29.77941176470588%) \n",
      "\n",
      "Total number of training and validation examples: 1898\n"
     ]
    }
   ],
   "source": [
    "# # make the splits\n",
    "# train_data, validation_test_data = train_test_split(satcen, test_size=0.25, stratify=y)\n",
    "# vt_y = [y[satcen.index(f)] for f in validation_test_data]\n",
    "# validation_data, test_data = train_test_split(validation_test_data, test_size=0.5, stratify=vt_y)\n",
    "\n",
    "# # check how many positive and negative observations are in each subset\n",
    "# print('### Train Data ###')\n",
    "# print('Size:', len(train_data))\n",
    "# train_pos = len([f for f in train_data if y[satcen.index(f)] == 1])\n",
    "# train_neg = len([f for f in train_data if y[satcen.index(f)] == 0])\n",
    "# print(f'Positive observations: {train_pos} ({train_pos / len(train_data) * 100}%)')\n",
    "# print(f'Negative observations: {train_neg} ({train_neg / len(train_data) * 100}%)', '\\n')\n",
    "\n",
    "# print('### Validation Data ###')\n",
    "# print('Size:', len(validation_data))\n",
    "# validation_pos = len([f for f in validation_data if y[satcen.index(f)] == 1])\n",
    "# validation_neg = len([f for f in validation_data if y[satcen.index(f)] == 0])\n",
    "# print(f'Positive observations: {validation_pos} ({validation_pos / len(validation_data) * 100}%)')\n",
    "# print(f'Negative observations: {validation_neg} ({validation_neg / len(validation_data) * 100}%)', '\\n')\n",
    "\n",
    "# print('### Test Data ###')\n",
    "# print('Size:', len(test_data))\n",
    "# test_pos = len([f for f in test_data if y[satcen.index(f)] == 1])\n",
    "# test_neg = len([f for f in test_data if y[satcen.index(f)] == 0])\n",
    "# print(f'Positive observations: {test_pos} ({test_pos / len(test_data) * 100}%)')\n",
    "# print(f'Negative observations: {test_neg} ({test_neg / len(test_data) * 100}%)', '\\n')\n",
    "\n",
    "# # remove all files currently in the train_valid folder\n",
    "# for f in os.listdir(satcen_path/'train_valid'):\n",
    "#     os.remove(satcen_path/'train_valid'/f)\n",
    "\n",
    "# # save training data\n",
    "# for f in train_data:\n",
    "#     src = satcen_path/'pictures'/f\n",
    "#     dst = satcen_path/'train_valid'/f\n",
    "#     shutil.copy(src, dst)\n",
    "\n",
    "# # save validation data\n",
    "# for f in validation_data:\n",
    "#     src = satcen_path/'pictures'/f\n",
    "#     dst = satcen_path/'train_valid'/f\n",
    "#     shutil.copy(src, dst)\n",
    "\n",
    "print('Total number of training and validation examples:', len(os.listdir(satcen_path/'train_valid')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f35d48ccabdbc3c8ccc3bd8f52698735896fba1ee0a9092f8afa0cc0b0bb74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
